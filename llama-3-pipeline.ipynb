{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8378985,"sourceType":"datasetVersion","datasetId":4982521},{"sourceId":8390943,"sourceType":"datasetVersion","datasetId":4988368},{"sourceId":8387061,"sourceType":"datasetVersion","datasetId":4988373},{"sourceId":8387161,"sourceType":"datasetVersion","datasetId":4988434},{"sourceId":8387192,"sourceType":"datasetVersion","datasetId":4988457},{"sourceId":8387238,"sourceType":"datasetVersion","datasetId":4988488},{"sourceId":33551,"sourceType":"modelInstanceVersion","modelInstanceId":28083}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-12T18:01:31.736670Z","iopub.execute_input":"2024-05-12T18:01:31.737078Z","iopub.status.idle":"2024-05-12T18:01:32.928501Z","shell.execute_reply.started":"2024-05-12T18:01:31.737044Z","shell.execute_reply":"2024-05-12T18:01:32.927164Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"! pip install langchain \n! pip install chromadb \n! pip install -U sentence-transformers\n! pip install tiktoken\n! pip install faiss-gpu\n! pip install InstructorEmbedding\n! pip install groq","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:01:32.930809Z","iopub.execute_input":"2024-05-12T18:01:32.931476Z","iopub.status.idle":"2024-05-12T18:04:05.718016Z","shell.execute_reply.started":"2024-05-12T18:01:32.931433Z","shell.execute_reply":"2024-05-12T18:04:05.716505Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nCollecting langchain-community<0.1,>=0.0.38 (from langchain)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nCollecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.57-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m869.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.57 orjson-3.10.3 packaging-23.2\nCollecting chromadb\n  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.31.0)\nRequirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.5.3)\nCollecting chroma-hnswlib==0.7.3 (from chromadb)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\nRequirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.4)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.15.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m647.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.1)\nRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\nRequirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.60.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.2.3)\nRequirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.1)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.10.3)\nRequirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.2)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\nRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\nRequirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\nRequirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nINFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\nCollecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.6)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (4.2.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.2.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\nDownloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\nDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\nDownloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\nDownloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\nDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=eca0e66dab105ed2d5540b25889dad61bf055779bdafccb4bfab75cbc1568d1f\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, mmh3, pyproject_hooks, opentelemetry-util-http, humanfriendly, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n  Attempting uninstall: kubernetes\n    Found existing installation: kubernetes 26.1.0\n    Uninstalling kubernetes-26.1.0:\n      Successfully uninstalled kubernetes-26.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.3 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 humanfriendly-10.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.7.0\nCollecting tiktoken\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.6.0\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nCollecting InstructorEmbedding\n  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\nDownloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: InstructorEmbedding\nSuccessfully installed InstructorEmbedding-1.0.1\nCollecting groq\n  Downloading groq-0.5.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.6)\nDownloading groq-0.5.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m721.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import DataLoader,Dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport transformers\nimport torch\nimport json\nfrom langchain.document_loaders import CSVLoader,TextLoader\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains.question_answering import load_qa_chain\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport time\nfrom tqdm.notebook import tqdm\nimport re\nimport time\nfrom InstructorEmbedding import INSTRUCTOR","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:04:05.719937Z","iopub.execute_input":"2024-05-12T18:04:05.720350Z","iopub.status.idle":"2024-05-12T18:04:15.757735Z","shell.execute_reply.started":"2024-05-12T18:04:05.720314Z","shell.execute_reply":"2024-05-12T18:04:15.756518Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"AmazonScience/mintaka\",trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:04:15.761079Z","iopub.execute_input":"2024-05-12T18:04:15.761861Z","iopub.status.idle":"2024-05-12T18:04:27.154541Z","shell.execute_reply.started":"2024-05-12T18:04:15.761816Z","shell.execute_reply":"2024-05-12T18:04:27.153476Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6200e75f8145d39d718dc186556719"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3036d29c186b40c594f173e99524b447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b7e49df1cd24b969fa7fa6dfd2e8bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/824k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"040df84d58ac4708a9b3a33f7dac7966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.57M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b73dfbc689743688007ddaab424b3fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6540d7bd024b58b3a8d26080b8fc14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eecf69f0f314589ae0b0fd674f812eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f880b774d59640ac9a9e073887e2de34"}},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"test\"].to_csv(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:04:27.155816Z","iopub.execute_input":"2024-05-12T18:04:27.156150Z","iopub.status.idle":"2024-05-12T18:04:28.055440Z","shell.execute_reply.started":"2024-05-12T18:04:27.156121Z","shell.execute_reply":"2024-05-12T18:04:28.053861Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08ffa1d55994b2590c8141e05bbf078"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"1556837"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\ndata = dataset['test']\n\ndataset2 = MyDataset(data)\n\ndf = pd.DataFrame([sample for sample in dataset2])\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:04:28.057098Z","iopub.execute_input":"2024-05-12T18:04:28.057549Z","iopub.status.idle":"2024-05-12T18:04:29.035853Z","shell.execute_reply.started":"2024-05-12T18:04:28.057517Z","shell.execute_reply":"2024-05-12T18:04:29.034528Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            id lang                                           question  \\\n0     fae46b21   en  What man was a famous American author and also...   \n1     bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n2     d2a03f72   en                 Who is older, The Weeknd or Drake?   \n3     9a296167   en           How many children did Donald Trump have?   \n4     e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n...        ...  ...                                                ...   \n3995  d52b03ee   en    Who was the first woman mayor of San Francisco?   \n3996  07f2947c   en  Where was the last Republican mayor of Boston ...   \n3997  58727fb0   en   How long was the 53rd mayor of Boston in office?   \n3998  a25818a2   en  Who was the first British monarch to have a pr...   \n3999  2761e54a   en  What is the oldest city building game develope...   \n\n              answerText    category complexityType  \\\n0             Mark Twain     history   intersection   \n1                      1      movies          count   \n2                  Drake       music    comparative   \n3                      5     history          count   \n4                     No  videogames          yesno   \n...                  ...         ...            ...   \n3995    Dianne Feinstein    politics        ordinal   \n3996     Portland, Maine    politics        ordinal   \n3997  20 years, 6 months    politics        ordinal   \n3998            George I    politics        ordinal   \n3999              Caesar  videogames    superlative   \n\n                                         questionEntity  \\\n0     [{'name': 'Q1497', 'entityType': 'entity', 'la...   \n1     [{'name': 'Q133313', 'entityType': 'entity', '...   \n2     [{'name': 'Q2121062', 'entityType': 'entity', ...   \n3     [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n4     [{'name': 'Q474573', 'entityType': 'entity', '...   \n...                                                 ...   \n3995  [{'name': 'Q62', 'entityType': 'entity', 'labe...   \n3996  [{'name': 'Q100', 'entityType': 'entity', 'lab...   \n3997  [{'name': 'Q100', 'entityType': 'entity', 'lab...   \n3998  [{'name': 'Q145', 'entityType': 'entity', 'lab...   \n3999  [{'name': 'Q588289', 'entityType': 'entity', '...   \n\n                                           answerEntity  \n0            [{'name': 'Q7245', 'label': 'Mark Twain'}]  \n1     [{'name': 'Q106291', 'label': 'Academy Award f...  \n2                [{'name': 'Q33240', 'label': 'Drake'}]  \n3     [{'name': 'Q3713655', 'label': 'Donald Trump J...  \n4                                                    []  \n...                                                 ...  \n3995  [{'name': 'Q230733', 'label': 'Dianne Feinstei...  \n3996          [{'name': 'Q49201', 'label': 'Portland'}]  \n3997                                                 []  \n3998  [{'name': 'Q130805', 'label': 'George I of Gre...  \n3999          [{'name': 'Q1025416', 'label': 'Caesar'}]  \n\n[4000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>lang</th>\n      <th>question</th>\n      <th>answerText</th>\n      <th>category</th>\n      <th>complexityType</th>\n      <th>questionEntity</th>\n      <th>answerEntity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fae46b21</td>\n      <td>en</td>\n      <td>What man was a famous American author and also...</td>\n      <td>Mark Twain</td>\n      <td>history</td>\n      <td>intersection</td>\n      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bc8713cc</td>\n      <td>en</td>\n      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n      <td>1</td>\n      <td>movies</td>\n      <td>count</td>\n      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d2a03f72</td>\n      <td>en</td>\n      <td>Who is older, The Weeknd or Drake?</td>\n      <td>Drake</td>\n      <td>music</td>\n      <td>comparative</td>\n      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9a296167</td>\n      <td>en</td>\n      <td>How many children did Donald Trump have?</td>\n      <td>5</td>\n      <td>history</td>\n      <td>count</td>\n      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e343ad26</td>\n      <td>en</td>\n      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n      <td>No</td>\n      <td>videogames</td>\n      <td>yesno</td>\n      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>d52b03ee</td>\n      <td>en</td>\n      <td>Who was the first woman mayor of San Francisco?</td>\n      <td>Dianne Feinstein</td>\n      <td>politics</td>\n      <td>ordinal</td>\n      <td>[{'name': 'Q62', 'entityType': 'entity', 'labe...</td>\n      <td>[{'name': 'Q230733', 'label': 'Dianne Feinstei...</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>07f2947c</td>\n      <td>en</td>\n      <td>Where was the last Republican mayor of Boston ...</td>\n      <td>Portland, Maine</td>\n      <td>politics</td>\n      <td>ordinal</td>\n      <td>[{'name': 'Q100', 'entityType': 'entity', 'lab...</td>\n      <td>[{'name': 'Q49201', 'label': 'Portland'}]</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>58727fb0</td>\n      <td>en</td>\n      <td>How long was the 53rd mayor of Boston in office?</td>\n      <td>20 years, 6 months</td>\n      <td>politics</td>\n      <td>ordinal</td>\n      <td>[{'name': 'Q100', 'entityType': 'entity', 'lab...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>a25818a2</td>\n      <td>en</td>\n      <td>Who was the first British monarch to have a pr...</td>\n      <td>George I</td>\n      <td>politics</td>\n      <td>ordinal</td>\n      <td>[{'name': 'Q145', 'entityType': 'entity', 'lab...</td>\n      <td>[{'name': 'Q130805', 'label': 'George I of Gre...</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>2761e54a</td>\n      <td>en</td>\n      <td>What is the oldest city building game develope...</td>\n      <td>Caesar</td>\n      <td>videogames</td>\n      <td>superlative</td>\n      <td>[{'name': 'Q588289', 'entityType': 'entity', '...</td>\n      <td>[{'name': 'Q1025416', 'label': 'Caesar'}]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"embedding = SentenceTransformerEmbeddings(model_name=\"hkunlp/instructor-xl\",model_kwargs={\"device\":\"cpu\"})","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:04:29.037533Z","iopub.execute_input":"2024-05-12T18:04:29.037887Z","iopub.status.idle":"2024-05-12T18:05:03.208622Z","shell.execute_reply.started":"2024-05-12T18:04:29.037858Z","shell.execute_reply":"2024-05-12T18:05:03.206984Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b53c323779d4449bb35b5bce5a195c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea70451b19b4004812a6a6d0f1c2c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593728ec35d042f88fd327cb9b65a99b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e890be0171f4ac8af39c090483b2855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a761edb7e024debb4c530f47262f594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb3dbbbb1265449ca46e1c985784e67b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"485762ebf4ec4ef5881b71a555b988b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26e677edcf142f28538f444fda36501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc94b1ff41ef4b37ac94c53e24aa3b99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98bb89bcaadd4bf28cd5175252bbdf1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9721f7b86b40fbb4d2cd9d34e5b7e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12eb4f5b52b042018c19ca06d9730c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06bd8ef5b8e04bcb8d11136f85d8e25e"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# genai.configure(api_key=\"AIzaSyBqsaV-w-UzdPn6Xf3ToljRrSnkXMBTdbA\")\n# genai.configure(api_key=\"AIzaSyC3334yqpk4njXkyy2zlGj5am3t51O1i08\")\n# model = genai.GenerativeModel('gemini-1.5-pro-latest')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:05:03.210244Z","iopub.execute_input":"2024-05-12T18:05:03.211066Z","iopub.status.idle":"2024-05-12T18:05:03.220659Z","shell.execute_reply.started":"2024-05-12T18:05:03.211013Z","shell.execute_reply":"2024-05-12T18:05:03.219250Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import groq\n\n# Replace with your actual Groq API key\nyour_api_key = \"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\"\n\n# Set up Groq client\nclient = groq.Client(api_key=your_api_key)\n# Define the prompt for Llama 3\n\n# Specify the Llama 3 model identifier\n  # Update with the specific version you want (e.g., \"llamada-70b\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:05:03.222301Z","iopub.execute_input":"2024-05-12T18:05:03.224309Z","iopub.status.idle":"2024-05-12T18:05:04.712055Z","shell.execute_reply.started":"2024-05-12T18:05:03.224252Z","shell.execute_reply":"2024-05-12T18:05:04.710101Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"embedding_path=f\"/kaggle/input/embedding-0-403\"","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:05:04.718002Z","iopub.execute_input":"2024-05-12T18:05:04.719180Z","iopub.status.idle":"2024-05-12T18:05:04.725439Z","shell.execute_reply.started":"2024-05-12T18:05:04.719107Z","shell.execute_reply":"2024-05-12T18:05:04.723302Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_context(question_id):\n    db_embeddings = FAISS.load_local(f\"{embedding_path}/embeddings/question_{question_id}\", embedding,allow_dangerous_deserialization=True)\n    retriever = db_embeddings.as_retriever(search_kwargs={\"k\":15})\n    top_triples = retriever.get_relevant_documents(df.iloc[question_id][\"question\"])\n    context=\"\"\n    for i in top_triples:\n        context+=i.page_content\n#     with open(f\"/kaggle/working/context_{question_id}.txt\",\"w\") as f:\n#         f.write(context)\n    return context","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:16.371946Z","iopub.execute_input":"2024-05-12T18:30:16.373122Z","iopub.status.idle":"2024-05-12T18:30:16.380525Z","shell.execute_reply.started":"2024-05-12T18:30:16.373080Z","shell.execute_reply":"2024-05-12T18:30:16.378853Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# def feed_question_without_context(question):\n#     prompt=f\"\"\"\n#     Give a one word answer to the given question. Also note if the answer is numeric, for example: 5, then respond as 5 and not \"\\Five\\\"\\n.\n#     Question:{question}\n#     \"\"\"\n#     response_without_context = model.generate_content(prompt)\n#     return response_without_context.text","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:16.385550Z","iopub.execute_input":"2024-05-12T18:30:16.386786Z","iopub.status.idle":"2024-05-12T18:30:16.396084Z","shell.execute_reply.started":"2024-05-12T18:30:16.386748Z","shell.execute_reply":"2024-05-12T18:30:16.394734Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"schema = memory_schema = {\n  \"type\": \"object\",\n  \"properties\": {\n    \"question\": {\n      \"type\": \"string\",\n      \"description\": \"the question asked\"\n    },\n    \"answer\": {\n      \"type\": \"string\",\n      \"description\": \"single phrase\"\n    },\n  }\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:16.397898Z","iopub.execute_input":"2024-05-12T18:30:16.398308Z","iopub.status.idle":"2024-05-12T18:30:16.411866Z","shell.execute_reply.started":"2024-05-12T18:30:16.398274Z","shell.execute_reply":"2024-05-12T18:30:16.410663Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model_id = \"llama3-8b-8192\"\nsystem_prompt=f\"\"\"Give a phrase to answer to the questions given below using only the Context given for each question. Also note if the answer is numeric, for example: 5, then respond as 5 and not \"\\Five\\\". Do not give any explanation \\n.\n    Write outputs in JSON in schema: {schema}\n    examples:\n    Context-0:A is father of B\n    B is father of C\n    Question-0:Is A grandfather of C?\n    Context-1:A is father of C\n    B is father of C\n    Question-1: Is A uncle of C?\n    Answer-0:Yes\n    Answer-1:No\\n\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:28.427473Z","iopub.execute_input":"2024-05-12T18:30:28.427907Z","iopub.status.idle":"2024-05-12T18:30:28.435823Z","shell.execute_reply.started":"2024-05-12T18:30:28.427875Z","shell.execute_reply":"2024-05-12T18:30:28.434480Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"errors=[]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:31.034340Z","iopub.execute_input":"2024-05-12T18:30:31.035144Z","iopub.status.idle":"2024-05-12T18:30:31.040339Z","shell.execute_reply.started":"2024-05-12T18:30:31.035104Z","shell.execute_reply":"2024-05-12T18:30:31.038984Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def feed_question_with_context(question,question_id):\n#     print(\"QUESTOIN = \",question)\n#     print(\"Question-id = \",question_id)\n    messages=[{\n                    \"role\": \"system\",\n                    \"content\": system_prompt,\n                }]\n    ans=[]\n    prompt=\"\"\n    try:\n        context = get_context(question_id)\n        prompt=f\"\"\"\n        Context-{question_id}:{context} \\n\n        Question-{question_id}:{question}\\n\n        \"\"\"\n\n    #         with open(f\"/kaggle/working/context_{question_id}.txt\",\"w\") as f:\n    #             f.write(context)\n        question_id+=1\n        messages.append({   \n                    \"role\": \"user\",\n                    \"content\": prompt,\n                })\n    \n        chat_completion = client.chat.completions.create(\n            messages=messages,\n            temperature=0.3,\n            model=model_id,\n            max_tokens=7500,\n            response_format={\"type\": \"json_object\"}\n        )\n        return chat_completion.choices[0].message.content\n    except Exception as e:\n        print(e)\n        errors.append(question_id)\n        return \"\"\n#     print(len(chat_completion))\n#     print(chat_completion.choices[0].message.content)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:32.818770Z","iopub.execute_input":"2024-05-12T18:30:32.819188Z","iopub.status.idle":"2024-05-12T18:30:32.828837Z","shell.execute_reply.started":"2024-05-12T18:30:32.819141Z","shell.execute_reply":"2024-05-12T18:30:32.827505Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# def feed_question_chain_of_thought(question,context):\n#     prompt=f\"\"\"\n#         Give proper chain of thought to answer the given question using given Context. Also note if the answer is numeric, for example: 5, then respond as 5 and not \"\\Five\\\"\\n.\n#         Context:{context}\\n\n#         Question:{question}\\n\n#         \"\"\"\n#     chain_of_thought_response = model.generate_content(prompt)\n#     return chain_of_thought_response.text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_path=f\"/kaggle/input/embedding-404-450\"\nl2=[179, 188, 197, 207, 214, 218, 241, 259, 324, 329, 359, 366, 387, 409, 413, 430, 431, 433, 439, 451, 477, 480, 505, 545, 603, 696, 697, 723, 724, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1151, 1298, 1311, 1314, 1315, 1316, 1317, 1323, 1332, 1389, 1429, 1430, 1434, 1437, 1441, 1445, 1454, 1739, 1822, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1948, 1951, 1962, 1965, 1989, 1999]\nstart=0\nend=len(l2)-1\nstep=1\nerrors=[]\nb=403\ne=450","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:36.571226Z","iopub.execute_input":"2024-05-12T18:30:36.572316Z","iopub.status.idle":"2024-05-12T18:30:36.592072Z","shell.execute_reply.started":"2024-05-12T18:30:36.572275Z","shell.execute_reply":"2024-05-12T18:30:36.590669Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"questions=list(df[\"question\"])\nanswers=list(df[\"answerText\"])\ncategory=list(df[\"category\"])\ncomplexity=list(df[\"complexityType\"])\nquestion_ids=list(df[\"id\"])\nf=open(f\"/kaggle/working/responses_{start}_{end}.txt\",\"w\")\nl=[]\nanswers_given=[]\nstart_curr=start\nfor st in tqdm(range(start,end+1,step)):\n    print(l2[st])\n    if l2[st]<b:\n        continue\n    if l2[st]>e:\n        break\n    \n    question_range=questions[l2[st]]\n#     print(\"Question Range = \",question_range)\n    answer_range=answers[l2[st]]\n    try:\n        llm_response = feed_question_with_context(question_range,l2[st])\n    except Exception as e:\n        print(e)\n        time.sleep(120)\n        print(\"TIME OUT\")\n       \n        continue\n#     ans_with_context=llm_response.split(\"\\n\")\n#     for answer in ans_with_context:\n#     print(f\"{llm_response}\")\n    l.append(llm_response)\n    f.write(llm_response)\n    f.write('\\n') \n    f.flush()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:30:38.114270Z","iopub.execute_input":"2024-05-12T18:30:38.114734Z","iopub.status.idle":"2024-05-12T18:30:51.625118Z","shell.execute_reply.started":"2024-05-12T18:30:38.114693Z","shell.execute_reply":"2024-05-12T18:30:51.623965Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d215a79995d54137b7639bad33ba10a8"}},"metadata":{}},{"name":"stdout","text":"179\n188\n197\n207\n214\n218\n241\n259\n324\n329\n359\n366\n387\n409\nError code: 400 - {'error': {'message': \"Failed to generate JSON. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'json_validate_failed', 'failed_generation': '{\\n\"question\": \"Which artist acted in Back to the Beach and was also a Disney Mouseketeer?\",\\n\"answer\": \"Frankie Avalon\"'}}\n413\n430\n431\n433\n439\n451\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('output.json', 'w') as json_file:\n    json.dump(l, json_file)\nprint(errors)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:31:06.838645Z","iopub.execute_input":"2024-05-12T18:31:06.839080Z","iopub.status.idle":"2024-05-12T18:31:06.846684Z","shell.execute_reply.started":"2024-05-12T18:31:06.839043Z","shell.execute_reply":"2024-05-12T18:31:06.845450Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"[410]\n","output_type":"stream"}]},{"cell_type":"code","source":"# prompt=f\"\"\"Give a phrase to answer to the questions given below using only the Context given for each question. Also note if the answer is numeric, for example: 5, then respond as 5 and not \"\\Five\\\"\\n.\n# Some examples:\n# Context-0:A is father of B\n# B is father of C\n# Question-0:Is A grandfather of C?\n# Context-1:A is father of C\n# B is father of C\n# Question-1: Is A uncle of C?\n# Answer-0:Yes\n# Answer-1:No\\n\n# \"\"\"\n# for question_id in range(len(questions)):\n#     context = get_context(question_id)\n#     prompt+=f\"\"\"\n#     Context-{question_id}:{context} \\n\n#     Question-{question_id}:{questions[question_id]}\\n\n#     \"\"\"\n\n\n# response_with_context = model.generate_content(prompt)\n# response_with_context.text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prompt=f\"\"\"Answer the questions given below using only the Context given for each question.\n# Some examples:\n# Context-0: A baker needs to decide how many cupcakes to bake for a party. They know there will be 10 children and 5 adults attending.\n# Question-0: How many cupcakes should the baker prepare in total?\n# Answer-0: The baker should prepare 15 cupcakes in total. (Reasoning: There are 10 children and 5 adults, so 10 + 5 = 15 people attending the party.)\n# Question-1: If the baker decides to bake 2 cupcakes per person, how many cupcakes will they need?\n# Answer-1:The baker will need 20 cupcakes in total. (Reasoning: There are 15 people attending (from the previous question), and they plan to bake 2 cupcakes per person, so 15 * 2 = 20 cupcakes.)\n# \"\"\"\n# questions = df.iloc[0:10][\"question\"]\n# answers = df.iloc[0:10][\"answerText\"]\n\n# for question_id in range(len(questions)):\n#     context = get_context(question_id)\n#     prompt+=f\"\"\"\n#     Context-{question_id}:{context}\n#     Question-{question_id}:{questions[question_id]}\\n\n#     \"\"\"\n# prompt+=f\"Give the chain of thought that helped you answer the given question from the provided context\"\n            \n# print(len(prompt))\n# response_with_context = model.generate_content(prompt)\n# response_with_context.text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prompt=f\"\"\"Give a phrase to answer to the questions given below using only the Context given for each question. Also note if the answer is numeric, for example: 5, then respond as 5 and not \"\\Five\\\"\\n.\n# Some examples:\n# Context-0:A is father of B\n# B is father of C\n# Question-0:Is A grandfather of C?\n# Context-1:A is father of C\n# B is father of C\n# Question-1: Is A uncle of C?\n# Answer-0:Yes\n# Answer-1:No\\n\n# \"\"\"\n# questions = df.iloc[0:10][\"question\"]\n# answers = df.iloc[0:10][\"answerText\"]\n# for question_id in range(len(questions)):\n#     context = get_context(question_id)\n#     prompt+=f\"\"\"\n#     Context-{question_id}:{context} \\n\n#     Question-{question_id}:{questions[question_id]}\\n\n#     \"\"\"\n# print(len(prompt))\n# response_with_context = model.generate_content(prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}